/**
 * Orchestrateur intelligent de transcription Whisper
 * G√®re l'analyse de qualit√©, l'am√©lioration audio, les fallbacks et la correction GPT
 */

const { checkAudioQuality } = require('./audioQualityChecker');
const { autoEnhance } = require('./audioEnhancer');
const { analyzeTranscriptionQuality } = require('./transcriptionQualityAnalyzer');
const { transcribeAudio } = require('../scripts/transcribeAudio');
const { formatWithGPT } = require('./gptFormatter');
const path = require('path');
const fs = require('fs');

/**
 * Configuration des strat√©gies de fallback Whisper
 * L'orchestrateur essaiera les mod√®les dans cet ordre selon la qualit√© audio
 */
const WHISPER_FALLBACK_STRATEGIES = [
  // Strat√©gie 1: Mod√®le tiny - Rapide pour audio de bonne qualit√©
  {
    name: 'TINY_FAST',
    modelSize: 'tiny',
    description: 'Mod√®le tiny (rapide, bonne qualit√© audio)',
    minAudioQuality: 70,
    estimatedSpeed: 'Tr√®s rapide (~3s pour 1min audio)'
  },
  // Strat√©gie 2: Mod√®le base - Bon compromis vitesse/pr√©cision
  {
    name: 'BASE_STANDARD',
    modelSize: 'base',
    description: 'Mod√®le base (compromis vitesse/pr√©cision)',
    minAudioQuality: 50,
    estimatedSpeed: 'Rapide (~10s pour 1min audio)'
  },
  // Strat√©gie 3: Mod√®le small - Meilleure pr√©cision
  {
    name: 'SMALL_BALANCED',
    modelSize: 'small',
    description: 'Mod√®le small (pr√©cision am√©lior√©e)',
    minAudioQuality: 30,
    estimatedSpeed: 'Moyen (~30s pour 1min audio)'
  },
  // Strat√©gie 4: Mod√®le medium - Haute pr√©cision pour audio difficile
  {
    name: 'MEDIUM_ROBUST',
    modelSize: 'medium',
    description: 'Mod√®le medium (haute pr√©cision)',
    minAudioQuality: 20,
    estimatedSpeed: 'Lent (~90s pour 1min audio)'
  },
  // Strat√©gie 5: Mod√®le large-v3 - Pr√©cision maximale en dernier recours
  {
    name: 'LARGE_ULTIMATE',
    modelSize: 'large-v3',
    description: 'Mod√®le large-v3 (pr√©cision maximale)',
    minAudioQuality: 0,
    estimatedSpeed: 'Tr√®s lent (~180s pour 1min audio)'
  }
];

/**
 * R√©sultat d'orchestration
 * @typedef {Object} OrchestrationResult
 * @property {boolean} success - Succ√®s de la transcription
 * @property {Object} audioQuality - Rapport de qualit√© audio
 * @property {Object} transcriptionQuality - Rapport de qualit√© de transcription
 * @property {Object} transcription - R√©sultat de transcription
 * @property {Object} enhancement - Informations sur l'am√©lioration audio
 * @property {Object} fallback - Informations sur les fallbacks utilis√©s
 * @property {Object} gptCorrection - Correction GPT si appliqu√©e
 * @property {string} finalAudioPath - Chemin du fichier audio utilis√©
 * @property {Array<string>} warnings - Avertissements
 * @property {string} userMessage - Message √† afficher √† l'utilisateur
 */

/**
 * Orchestre la transcription compl√®te avec gestion intelligente de la qualit√©
 * @param {string} audioPath - Chemin du fichier audio
 * @param {Object} options - Options de transcription
 * @param {string} options.modelSize - Taille du mod√®le Whisper (d√©faut: 'base')
 * @param {string} options.language - Langue (d√©faut: null = auto)
 * @param {boolean} options.autoEnhance - Am√©lioration audio automatique (d√©faut: true)
 * @param {boolean} options.useFallback - Utiliser les fallbacks (d√©faut: true)
 * @param {boolean} options.useGPTCorrection - Correction GPT si qualit√© faible (d√©faut: true)
 * @param {string} options.openaiApiKey - Cl√© API OpenAI
 * @returns {Promise<OrchestrationResult>}
 */
async function orchestrateTranscription(audioPath, options = {}) {
  const {
    modelSize = 'large-v3',
    language = null,
    autoEnhance: autoEnhanceEnabled = true,
    useFallback = true,
    useGPTCorrection = true,
    openaiApiKey = null
  } = options;

  console.log('\nüé¨ === ORCHESTRATION INTELLIGENTE DE TRANSCRIPTION ===');
  console.log(`üìÅ Fichier: ${path.basename(audioPath)}`);
  console.log(`ü§ñ Mod√®le initial: ${modelSize}`);
  console.log(`üîß Am√©lioration auto: ${autoEnhanceEnabled ? 'OUI' : 'NON'}`);
  console.log(`üîÑ Fallbacks: ${useFallback ? 'OUI' : 'NON'}`);
  console.log(`üß† Correction GPT: ${useGPTCorrection ? 'OUI' : 'NON'}`);

  const result = {
    success: false,
    audioQuality: null,
    transcriptionQuality: null,
    transcription: null,
    enhancement: null,
    fallback: null,
    gptCorrection: null,
    finalAudioPath: audioPath,
    warnings: [],
    userMessage: ''
  };

  try {
    // √âTAPE 1: Analyse de la qualit√© audio
    console.log('\nüìç √âTAPE 1: Analyse de la qualit√© audio');
    const audioQualityReport = await checkAudioQuality(audioPath);
    result.audioQuality = audioQualityReport;

    let workingAudioPath = audioPath;

    // √âTAPE 2: Am√©lioration audio si n√©cessaire
    if (autoEnhanceEnabled && audioQualityReport.needsEnhancement) {
      console.log('\nüìç √âTAPE 2: Am√©lioration audio n√©cessaire');
      try {
        const enhancement = await autoEnhance(audioPath, audioQualityReport);
        result.enhancement = enhancement;
        workingAudioPath = enhancement.enhancedPath;
        result.finalAudioPath = workingAudioPath;
        
        console.log(`‚úÖ Audio am√©lior√©: ${path.basename(workingAudioPath)}`);
        result.warnings.push(`Audio am√©lior√© avec preset ${enhancement.preset}`);
      } catch (enhanceError) {
        console.error(`‚ö†Ô∏è  √âchec am√©lioration audio: ${enhanceError.message}`);
        result.warnings.push(`Impossible d'am√©liorer l'audio: ${enhanceError.message}`);
      }
    } else if (!audioQualityReport.needsEnhancement) {
      console.log('\nüìç √âTAPE 2: Qualit√© audio acceptable, pas d\'am√©lioration n√©cessaire');
    } else {
      console.log('\nüìç √âTAPE 2: Am√©lioration audio d√©sactiv√©e');
    }

    // √âTAPE 3: Tentative de transcription avec strat√©gie de fallback intelligente
    console.log('\nüìç √âTAPE 3: Transcription avec Whisper (strat√©gie adaptative)');
    
    let transcription = null;
    let transcriptionQualityReport = null;
    let usedStrategy = null;
    const attemptedStrategies = [];

    // Construire la liste des strat√©gies √† essayer
    let strategies;
    
    if (useFallback) {
      // Filtrer les strat√©gies selon la qualit√© audio
      const audioScore = audioQualityReport.qualityScore;
      strategies = WHISPER_FALLBACK_STRATEGIES.filter(s => audioScore >= s.minAudioQuality);
      
      console.log(`   üìä Qualit√© audio: ${audioScore}/100 ‚Üí ${strategies.length} strat√©gies disponibles`);
      
      // Si aucune strat√©gie ne correspond, utiliser toutes les strat√©gies
      if (strategies.length === 0) {
        console.log(`   ‚ö†Ô∏è  Audio de tr√®s mauvaise qualit√©, tentative avec tous les mod√®les`);
        strategies = WHISPER_FALLBACK_STRATEGIES;
      }
    } else {
      // Mode manuel: utiliser uniquement le mod√®le sp√©cifi√©
      strategies = [{ 
        name: 'USER_SPECIFIED', 
        modelSize, 
        description: `Mod√®le ${modelSize} sp√©cifi√©`,
        estimatedSpeed: 'Variable'
      }];
    }

    // Essayer chaque strat√©gie jusqu'√† obtenir une transcription acceptable
    for (let i = 0; i < strategies.length; i++) {
      const strategy = strategies[i];
      const isLastStrategy = i === strategies.length - 1;
      
      console.log(`\n   üîÑ Tentative ${i + 1}/${strategies.length}: ${strategy.description}`);
      console.log(`      Mod√®le: ${strategy.modelSize} | Vitesse: ${strategy.estimatedSpeed || 'N/A'}`);
      attemptedStrategies.push(strategy.name);

      try {
        const startTime = Date.now();
        
        // Transcription
        transcription = await transcribeAudio(workingAudioPath, strategy.modelSize, language);
        
        const duration = ((Date.now() - startTime) / 1000).toFixed(1);
        console.log(`      ‚è±Ô∏è  Temps de transcription: ${duration}s`);
        
        // Analyse de qualit√©
        transcriptionQualityReport = analyzeTranscriptionQuality(transcription);
        
        console.log(`      üìä Qualit√© transcription: ${transcriptionQualityReport.qualityScore}/100 (${transcriptionQualityReport.qualityLevel})`);
        console.log(`      üìù Segments obtenus: ${transcription.segments.length}`);
        
        // Si la qualit√© est acceptable, on arr√™te
        if (transcriptionQualityReport.isAcceptable) {
          console.log(`   ‚úÖ Transcription acceptable obtenue avec ${strategy.modelSize}`);
          usedStrategy = strategy;
          break;
        } else {
          console.log(`   ‚ö†Ô∏è  Qualit√© insuffisante avec ${strategy.modelSize}`);
          
          // Si c'est la derni√®re strat√©gie, on garde quand m√™me le r√©sultat
          if (isLastStrategy) {
            console.log(`   ‚ÑπÔ∏è  Derni√®re strat√©gie, conservation du meilleur r√©sultat disponible`);
            usedStrategy = strategy;
          } else {
            console.log(`   üîÑ Passage au mod√®le suivant: ${strategies[i + 1].modelSize}`);
          }
        }
      } catch (transcribeError) {
        console.error(`   ‚ùå √âchec avec ${strategy.modelSize}: ${transcribeError.message}`);
        
        // Si c'est la derni√®re strat√©gie, on propage l'erreur
        if (isLastStrategy) {
          throw transcribeError;
        } else {
          console.log(`   üîÑ Tentative avec le mod√®le suivant...`);
        }
      }
    }

    result.transcription = transcription;
    result.transcriptionQuality = transcriptionQualityReport;
    result.fallback = {
      strategiesAttempted: attemptedStrategies,
      usedStrategy: usedStrategy?.name,
      usedModel: usedStrategy?.modelSize
    };

    // √âTAPE 4: Correction GPT si qualit√© insuffisante
    if (useGPTCorrection && transcriptionQualityReport && !transcriptionQualityReport.isAcceptable) {
      console.log('\nüìç √âTAPE 4: Correction GPT n√©cessaire');
      
      if (!openaiApiKey) {
        console.log('   ‚ö†Ô∏è  Cl√© API OpenAI non fournie, correction GPT ignor√©e');
        result.warnings.push('Correction GPT non disponible (cl√© API manquante)');
      } else {
        try {
          console.log('   üß† Envoi √† GPT-4o-mini pour correction...');
          
          // Pr√©parer les segments pour GPT
          const segments = transcription.segments.map(s => ({
            start: s.start,
            end: s.end,
            text: s.text
          }));

          const gptResult = await formatWithGPT(segments, openaiApiKey);
          result.gptCorrection = gptResult;
          
          console.log(`   ‚úÖ Correction GPT appliqu√©e`);
          console.log(`   üìù R√©sum√©: ${gptResult.summary}`);
          result.warnings.push('Transcription corrig√©e par GPT-4o-mini');
        } catch (gptError) {
          console.error(`   ‚ö†Ô∏è  √âchec correction GPT: ${gptError.message}`);
          result.warnings.push(`Correction GPT √©chou√©e: ${gptError.message}`);
        }
      }
    } else if (transcriptionQualityReport?.isAcceptable) {
      console.log('\nüìç √âTAPE 4: Qualit√© acceptable, correction GPT non n√©cessaire');
    } else {
      console.log('\nüìç √âTAPE 4: Correction GPT d√©sactiv√©e');
    }

    // √âTAPE 5: D√©terminer le succ√®s et g√©n√©rer le message utilisateur
    result.success = transcription !== null;
    result.userMessage = generateUserMessage(result);

    console.log('\n‚úÖ === ORCHESTRATION TERMIN√âE ===');
    console.log(`üìä Qualit√© audio: ${audioQualityReport.qualityLevel} (${audioQualityReport.qualityScore}/100)`);
    console.log(`üìä Qualit√© transcription: ${transcriptionQualityReport?.qualityLevel || 'N/A'} (${transcriptionQualityReport?.qualityScore || 0}/100)`);
    console.log(`üéØ Succ√®s: ${result.success ? 'OUI' : 'NON'}`);
    
    if (result.warnings.length > 0) {
      console.log(`‚ö†Ô∏è  Avertissements: ${result.warnings.length}`);
      result.warnings.forEach(w => console.log(`   - ${w}`));
    }

    return result;

  } catch (error) {
    console.error('\n‚ùå === ERREUR ORCHESTRATION ===');
    console.error(error);
    
    result.success = false;
    result.userMessage = generateErrorMessage(error, result);
    
    throw error;
  }
}

/**
 * G√©n√®re un message utilisateur clair bas√© sur le r√©sultat
 * @param {OrchestrationResult} result - R√©sultat de l'orchestration
 * @returns {string} Message pour l'utilisateur
 */
function generateUserMessage(result) {
  const messages = [];

  // Message principal selon la qualit√©
  if (!result.transcription) {
    messages.push('‚ùå La transcription a √©chou√©.');
  } else if (result.transcriptionQuality?.qualityLevel === 'GOOD') {
    messages.push('‚úÖ Transcription de bonne qualit√© obtenue.');
  } else if (result.transcriptionQuality?.qualityLevel === 'ACCEPTABLE') {
    messages.push('‚úÖ Transcription acceptable obtenue.');
  } else if (result.transcriptionQuality?.qualityLevel === 'POOR') {
    messages.push('‚ö†Ô∏è Transcription de qualit√© m√©diocre. Les r√©sultats peuvent √™tre impr√©cis.');
  } else {
    messages.push('‚ùå Transcription de tr√®s mauvaise qualit√©. Les r√©sultats sont probablement inutilisables.');
  }

  // Informations sur la qualit√© audio
  if (result.audioQuality) {
    if (result.audioQuality.qualityLevel === 'POOR' || result.audioQuality.qualityLevel === 'UNUSABLE') {
      messages.push(`\nüîä Qualit√© audio: ${result.audioQuality.qualityLevel}`);
      messages.push('Probl√®mes d√©tect√©s:');
      result.audioQuality.issues.forEach(issue => {
        messages.push(`  ‚Ä¢ ${issue.message}`);
      });
    }
  }

  // Informations sur l'am√©lioration
  if (result.enhancement) {
    messages.push(`\nüîß Audio am√©lior√© automatiquement (preset: ${result.enhancement.preset})`);
  }

  // Informations sur les fallbacks
  if (result.fallback && result.fallback.strategiesAttempted.length > 1) {
    messages.push(`\nüîÑ ${result.fallback.strategiesAttempted.length} mod√®les test√©s`);
    messages.push(`Mod√®le final utilis√©: ${result.fallback.usedModel}`);
  } else if (result.fallback && result.fallback.usedModel) {
    messages.push(`\nü§ñ Mod√®le utilis√©: ${result.fallback.usedModel}`);
  }

  // Informations sur la correction GPT
  if (result.gptCorrection) {
    messages.push('\nüß† Transcription corrig√©e par GPT-4o-mini');
  }

  // Recommandations
  if (result.transcriptionQuality && result.transcriptionQuality.recommendations.length > 0) {
    messages.push('\nüí° Recommandations:');
    result.transcriptionQuality.recommendations.slice(0, 3).forEach(rec => {
      messages.push(`  ‚Ä¢ ${rec}`);
    });
  }

  return messages.join('\n');
}

/**
 * G√©n√®re un message d'erreur clair pour l'utilisateur
 * @param {Error} error - Erreur survenue
 * @param {OrchestrationResult} result - R√©sultat partiel
 * @returns {string} Message d'erreur
 */
function generateErrorMessage(error, result) {
  const messages = [
    '‚ùå Impossible de transcrire le fichier audio.',
    `\nErreur: ${error.message}`
  ];

  // Ajouter des informations contextuelles si disponibles
  if (result.audioQuality) {
    if (result.audioQuality.qualityLevel === 'UNUSABLE') {
      messages.push('\nüîä La qualit√© audio est trop mauvaise pour √™tre transcrite.');
      messages.push('Veuillez fournir un fichier audio de meilleure qualit√©.');
    } else if (result.audioQuality.issues.length > 0) {
      messages.push('\nüîä Probl√®mes audio d√©tect√©s:');
      result.audioQuality.issues.slice(0, 3).forEach(issue => {
        messages.push(`  ‚Ä¢ ${issue.message}`);
      });
    }
  }

  // Recommandations g√©n√©rales
  messages.push('\nüí° Suggestions:');
  messages.push('  ‚Ä¢ V√©rifiez que le fichier contient bien du contenu audio parl√©');
  messages.push('  ‚Ä¢ Assurez-vous que le volume est suffisant');
  messages.push('  ‚Ä¢ R√©duisez le bruit de fond si possible');
  messages.push('  ‚Ä¢ Essayez avec un fichier audio de meilleure qualit√©');

  return messages.join('\n');
}

module.exports = {
  orchestrateTranscription,
  WHISPER_FALLBACK_STRATEGIES
};
